<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Ankit Singh Rawat</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Ankit Singh Rawat</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="talks.html">Talks</a></div>
<div class="menu-item"><a href="services.html">Services</a></div>
<div class="menu-item"><a href="cv.pdf">Curriculum&nbsp;Vitae</a></div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=U0_ab4cAAAAJ&hl=en">Google&nbsp;Scholar</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Ankit Singh Rawat</h1>
</div>
<table class="imgtable"><tr><td>
<img src="webpage.jpg" alt="" />&nbsp;</td>
<td align="left"><p><a href="https://research.google/">Google Research NY</a> <br />
111 8th Avenue <br />
New York, NY 10011, USA <br />
E-mail: ankitsrawat AT google(dot)com</p>
</td></tr></table>
<h2>About Me</h2>
<p>I am a Research Scientist at Google Research, New York.</p>
<p>Previously, I held postdoctoral appointments at <a href="http://web.mit.edu/">Massachusetts Institute of Technology</a>, <a href="http://www.cmu.edu">Carnegie Mellon University</a>, and <a href="http://www.umass.edu/">University of Massachusetts Amherst</a>, where I worked with <a href="http://allegro.mit.edu/~gww/">Prof. Gregory W. Wornell</a>, <a href="http://www.cs.cmu.edu/~venkatg/">Prof. Venkatesan Guruswami</a>, and <a href="https://people.cs.umass.edu/~arya/">Prof. Arya Mazumdar</a>, respectively. I received a Ph.D. in Electrical and Computer Engineering from <a href="http://www.utexas.edu">The University of Texas at Austin</a> in 2015, where I was advised by <a href="http://sriram.utlinc.org/">Prof. Sriram Vishwanath</a>. At UT Austin, I also had the pleasure of working with <a href="http://users.ece.utexas.edu/~dimakis/">Prof. Alex Dimakis</a>. Before attending UT Austin, I received a B.Tech. degree in Electrical Engineering from <a href="http://www.iitk.ac.in">Indian Institute of Technology (IIT) Kanpur</a> in 2010. <br /></p>
<h2>Research Interests</h2>
<ul>
<li><p>Large Scale Machine Learning</p>
</li>
<li><p>Coding Theory</p>
</li>
<li><p>Information Theory</p>
</li>
</ul>
<h2>News</h2>
<ul>
<li><p>New preprints.</p>
<ul>
<li><p><a href="https://arxiv.org/abs/2012.00363">Modifying Memories in Transformer Models.</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2102.06849">Distilling Double Descent.</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2102.03349">On the Reproducibility of Neural Network Predictions.</a></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>Two papers accepted at ICLR 2021.</p>
<ul>
<li><p><a href="https://openreview.net/forum?id=jphnJNOwe36">Overparameterisation and Worst-case Generalisation: Friend or Foe?</a></p>
</li>
<li><p><a href="https://openreview.net/forum?id=37nvvqkCo5">Long-tail Learning via Logit Adjustment.</a></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>One paper accepted at AISTATS 2021.</p>
<ul>
<li><p><a href="http://proceedings.mlr.press/v130/reddi21a.html">RankDistil: Knowledge Distillation for Ranking.</a></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>Three papers accepted at NeurIPS 2020.</p>
<ul>
<li><p><a href="https://papers.nips.cc/paper/2020/hash/9ed27554c893b5bad850a422c3538c15-Abstract.html">O(n) Connections are Expressive Enough: Universal Approximability of Sparse Transformers.</a></p>
</li>
<li><p><a href="https://papers.nips.cc/paper/2020/hash/837a7924b8c0aa866e41b2721f66135c-Abstract.html">Adversarial Robustness via Robust Low Rank Representations.</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2004.05465">Robust Large-Margin Learning in Hyperbolic Space.</a></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>Two papers accepted at ICML 2020.</p>
<ul>
<li><p><a href="https://arxiv.org/abs/2004.10342">Federated Learning with Only Positive Labels.</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2002.07028">Low-Rank Bottleneck in Multi-head Attention Models.</a></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>2020 EURASIP JASP Best Paper Award for this <a href="https://link.springer.com/article/10.1186/s13634-015-0292-0">paper</a> coauthored with <a href="https://people.cs.umass.edu/~arya/">Arya Mazumdar</a> and <a href="http://sriram.utlinc.org/">Sriram Vishwanath</a>.</p>
</li>
</ul>
<ul>
<li><p>New preprints.</p>
<ul>
<li><p><a href="https://arxiv.org/abs/2005.10419">Why distillation helps: a statistical perspective.</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2004.10915">Doubly-stochastic mining for heterogeneous retrieval.</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2004.05465">Robust Large-Margin Learning in Hyperbolic Space.</a></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>Two papers appeared at ICLR 2020.</p>
<ul>
<li><p><a href="https://openreview.net/forum?id=rklB76EKPr">Can Gradient Clipping Mitigate Label Noise?</a></p>
</li>
<li><p><a href="https://openreview.net/forum?id=ByxRM0Ntvr">Are Transformers Universal Approximators of Sequence-to-sequence Functions?</a></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>One paper accepted at ISIT 2020.</p>
<ul>
<li><p><a href="https://arxiv.org/abs/2002.08892">Reliable Distributed Clustering with Redundant Data Assignment.</a></p>
</li>
</ul>

</li>
</ul>
<h2>Selected Publications (<a href="publications.html">Full List</a>)</h2>
<ul>
<li><p><a href="https://openreview.net/forum?id=37nvvqkCo5">Long-tail Learning via Logit Adjustment</a><br />
Aditya Krishna Menon, Sadeep Jayasumana, Ankit Singh Rawat, Himanshu Jain, Andreas Veit, Sanjiv Kumar <br />
<b>Spotlight</b>, To appear in <i>International Conference on Learning Representations (ICLR)</i>, 2021.</p>
</li>
</ul>
<ul>
<li><p><a href="https://papers.nips.cc/paper/2020/hash/9ed27554c893b5bad850a422c3538c15-Abstract.html">O(n) Connections are Expressive Enough: Universal Approximability of Sparse Transformers</a><br />
Chulhee Yun, Yin-Wen Chang, Srinadh Bhojanapalli, Ankit Singh Rawat, Sashank J. Reddi, Sanjiv Kumar <br />
<i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2020.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2004.10342">Federated Learning with Only Positive Labels</a><br />
Felix X. Yu, Ankit Singh Rawat, Aditya Krishna Menon, Sanjiv Kumar <br />
<i>International Conference on Machine Learning (ICML)</i>, 2020.</p>
</li>
</ul>
<ul>
<li><p><a href="https://openreview.net/forum?id=rklB76EKPr">Can Gradient Clipping Mitigate Label Noise?</a><br />
Aditya Krishna Menon, Ankit Singh Rawat, Sashank J. Reddi, Sanjiv Kumar <br />
<i>International Conference on Learning Representations (ICLR)</i>, 2020.</p>
</li>
</ul>
<ul>
<li><p><a href="https://openreview.net/forum?id=ByxRM0Ntvr">Are Transformers Universal Approximators of Sequence-to-sequence Functions?</a><br />
Chulhee Yun, Srinadh Bhojanapalli, Ankit Singh Rawat, Sashank J. Reddi, Sanjiv Kumar <br />
<i>International Conference on Learning Representations (ICLR)</i>, 2020.
</p>
</li>
</ul>
<ul>
<li><p><a href="https://papers.nips.cc/paper/9245-multilabel-reductions-what-is-my-loss-optimising">Multilabel Reductions: What is My Loss Optimising?</a><br />
Aditya Krishna Menon, Ankit Singh Rawat, Sashank J. Reddi, Sanjiv Kumar <br />
<b>Spotlight</b>, <i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2019.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1907.10747">Sampled Softmax with Random Fourier Features</a><br />
Ankit Singh Rawat, Jiecao Chen, Felix Yu, Ananda Theertha Suresh, Sanjiv Kumar <br />
<i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2019.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1805.08327">Robust Gradient Descent via Moment Encoding with LDPC Codes</a><br />
Raj Kumar Maity, Ankit Singh Rawat, Arya Mazumdar <br />
<i>IEEE International Symposium on Information Theory (ISIT)</i>, 2019.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1712.03638">Lifting High-dimensional Nonlinear Models with Gaussian Regressors</a><br />
Christos Thrampoulidis, Ankit Singh Rawat <br /> 
<i>22nd International Conference on Artificial Intelligence and Statistics (AISTATS)</i>, 2019.</p>
</li>
</ul>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/8303716/">MDS Code Constructions with Small Sub-packetization and Near-optimal Repair Bandwidth</a><br />
Ankit Singh Rawat, Itzhak Tamo, Venkatesan Guruswami, Klim Efremenko<br />
<i>IEEE Transactions on Information Theory</i>, October 2018.</p>
</li>
</ul>
<ul>
<li><p><a href="http://ieeexplore.ieee.org/document/7398062/">Locality and Availability in Distributed Storage</a><br />
Ankit Singh Rawat, Dimitris S. Papailiopoulos, Alexandros G. Dimakis, Sriram Vishwanath<br />
<i>IEEE Transactions on Information Theory</i>, August 2016.</p>
</li>
</ul>
<ul>
<li><p><a href="http://ieeexplore.ieee.org/document/7396954/">Batch Codes through Dense Graphs with High Girth</a><br />
Ankit Singh Rawat, Zhao Song, Alexandros G. Dimakis, Anna Gal <br />
<i>IEEE Transactions on Information Theory</i>, April 2016.</p>
</li>
</ul>
<ul>
<li><p><a href="https://papers.nips.cc/paper/5915-associative-memory-via-a-sparse-recovery-model">Associative Memory via a Sparse Recovery Model</a><br />
Arya Mazumdar, Ankit Singh Rawat<br />
<i>Advances in Neural Information Processing Systems (NeurIPS)</i>, December 2015.</p>
</li>
</ul>
<ul>
<li><p><a href="http://ieeexplore.ieee.org/document/6655894/">Optimal Locally Repairable and Secure Codes for Distributed Storage Systems</a><br />
Ankit Singh Rawat, O. Ozan Koyluoglu, Natalia Silberstein, Sriram Vishwanath<br />
<i>IEEE Transactions on Information Theory</i>, January 2014.</p>
</li>
</ul>
<p>Click <a href="publications.html">here</a> for the full list of publications.</p>
<p><meta name="google-site-verification" content="MQyPNO29SDiSP-QF1z3KuK8sKx8S2HU20q6WLYngfrc" /></p>
<div id="footer">
<div id="footer-text">
Page generated 2021-03-21 13:20:11 EDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
